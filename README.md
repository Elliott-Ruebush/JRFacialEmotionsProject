# JRFacialEmotionsProject
Research project comparing facial emotional recognition among machine learning algorithms and humans.

<b>Abstract</b>

This experiment examined the question of how machine learning methods compare to humans in their capability to detect emotions based 
off facial expression. Three different machine learning facial recognition methods were used to perform facial emotional recognition on 
the extended Cohn-Kanade dataset, and humans were asked to assign emotion to a set of images from the same dataset. I hypothesised that 
humans would be more accurate than machine learning methods, which would vary somewhat in accuracy and be generally lower in accuracy 
than humans. In the end, for the specific emotions compared, the results of the experiment showed surprising similarity (approx. 
10% difference) in the accuracy of the Fisherfaces method and the accuracy of human emotional evaluation.
